{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision\n",
        "!pip install conllu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRp0U-TAm2h9",
        "outputId": "5fd01c88-a0dd-42b5-940d-70cce5a03ca4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.17.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n",
            "Collecting conllu\n",
            "  Downloading conllu-4.5.3-py2.py3-none-any.whl (16 kB)\n",
            "Installing collected packages: conllu\n",
            "Successfully installed conllu-4.5.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss(ignore_index=-1)"
      ],
      "metadata": {
        "id": "HKPYgQVeqnF7"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class DependencyParser(nn.Module):\n",
        "    def __init__(self, vocab_size, pos_size, embedding_dim, hidden_dim, output_dim):\n",
        "        super(DependencyParser, self).__init__()\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.pos_embeddings = nn.Embedding(pos_size, embedding_dim)\n",
        "        self.fc1 = nn.Linear(2 * embedding_dim, hidden_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim) #SHIFT, LEFT-ARC, RIGHT-ARC\n",
        "\n",
        "    def forward(self, x):\n",
        "        word_embeds = self.word_embeddings(x[:, :, 0])\n",
        "        pos_embeds = self.pos_embeddings(x[:, :, 1])\n",
        "        embeds = torch.cat((word_embeds, pos_embeds), dim=2)\n",
        "        x = self.fc1(embeds)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Model and DataLoader Setup\n",
        "vocab_size = len(train_dataset.word_index) + 1\n",
        "pos_size = len(train_dataset.pos_index) + 1\n",
        "model = DependencyParser(vocab_size, pos_size, embedding_dim=100, hidden_dim=200, output_dim=3)\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=-1)\n",
        "\n",
        "# Training Function\n",
        "def train(model, train_loader, optimizer, criterion, epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for features, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(features)\n",
        "            outputs = outputs.transpose(1, 2)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f'Epoch {epoch+1}, Loss: {total_loss / len(train_loader)}')\n",
        "\n",
        "train(model, train_loader, optimizer, criterion)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_pusnS3qoaR",
        "outputId": "a5121e89-edd9-4114-94e5-37e89ba0343f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.016724249358661354\n",
            "Epoch 2, Loss: 8.294955272021424e-05\n",
            "Epoch 3, Loss: 2.9474748474485193e-05\n",
            "Epoch 4, Loss: 1.4661742574278425e-05\n",
            "Epoch 5, Loss: 8.548370660765632e-06\n",
            "Epoch 6, Loss: 5.451718092727992e-06\n",
            "Epoch 7, Loss: 3.6755631188089883e-06\n",
            "Epoch 8, Loss: 2.575452059000336e-06\n",
            "Epoch 9, Loss: 1.8546004304894547e-06\n",
            "Epoch 10, Loss: 1.372853632534891e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = DependencyParsingDataset('/content/en_ewt-ud-train.conllu')\n",
        "dev_dataset = DependencyParsingDataset('/content/en_ewt-ud-dev.conllu')"
      ],
      "metadata": {
        "id": "hwcyqh2AroQo"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from collections import defaultdict\n",
        "from conllu import parse_incr\n",
        "import os\n",
        "\n",
        "class DependencyParsingDataset(Dataset):\n",
        "    def __init__(self, file_path):\n",
        "        self.vocab = defaultdict(lambda: len(self.vocab))  # Proper initialization\n",
        "        self.tag_vocab = defaultdict(lambda: len(self.tag_vocab))  # Proper initialization\n",
        "        self.data = self.load_data(file_path)\n",
        "\n",
        "    def load_data(self, file_path):\n",
        "        data = []\n",
        "        if not os.path.exists(file_path):\n",
        "            raise FileNotFoundError(f\"The file {file_path} does not exist.\")\n",
        "        with open(file_path, 'r', encoding='utf-8') as file:\n",
        "            for tokenlist in parse_incr(file):\n",
        "                indexed_tokens = [\n",
        "                    (self.vocab[token['form'].lower()], self.tag_vocab[token['upostag']])\n",
        "                    for token in tokenlist if 'form' in token and 'upostag' in token\n",
        "                ]\n",
        "                data.append((indexed_tokens, []))  # Second element is placeholder for targets\n",
        "        return data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n",
        "\n",
        "# Ensure that the file path is correct and the .conllu file is accessible\n",
        "train_dataset = DependencyParsingDataset('/content/en_ewt-ud-train.conllu')\n",
        "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
        "\n",
        "print(\"Loaded training dataset with\", len(train_dataset), \"items.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytTuzQbvsM_2",
        "outputId": "3c0a61b7-3a8d-42a0-8b1e-eda8956e8ae2"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Dataset Samples:\n",
            "Sample 1 - Features: tensor([[ 0,  0],\n",
            "        [ 1,  1],\n",
            "        [ 2,  0],\n",
            "        [ 3,  1],\n",
            "        [ 4,  2],\n",
            "        [ 5,  3],\n",
            "        [ 6,  4],\n",
            "        [ 7,  0],\n",
            "        [ 8,  0],\n",
            "        [ 0,  0],\n",
            "        [ 1,  1],\n",
            "        [ 9,  0],\n",
            "        [10,  1],\n",
            "        [11,  5],\n",
            "        [12,  3],\n",
            "        [13,  6],\n",
            "        [11,  5],\n",
            "        [14,  3],\n",
            "        [15,  6],\n",
            "        [11,  5],\n",
            "        [16,  3],\n",
            "        [17,  6],\n",
            "        [18,  0],\n",
            "        [10,  1],\n",
            "        [19,  6],\n",
            "        [11,  5],\n",
            "        [20,  2],\n",
            "        [21,  3],\n",
            "        [22,  1]]), Labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0])\n",
            "Sample 2 - Features: tensor([[23,  1],\n",
            "        [24,  5],\n",
            "        [25,  3],\n",
            "        [17,  6],\n",
            "        [26,  5],\n",
            "        [27,  2],\n",
            "        [28,  3],\n",
            "        [29,  7],\n",
            "        [30,  7],\n",
            "        [31,  4],\n",
            "        [32,  8],\n",
            "        [33,  3],\n",
            "        [34,  6],\n",
            "        [35,  3],\n",
            "        [36,  9],\n",
            "        [37,  4],\n",
            "        [22,  1],\n",
            "        [38,  1]]), Labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "Sample 3 - Features: tensor([[39,  0],\n",
            "        [ 3,  1],\n",
            "        [40,  2],\n",
            "        [41,  3],\n",
            "        [42,  4],\n",
            "        [43, 10],\n",
            "        [44,  8],\n",
            "        [45,  7],\n",
            "        [46,  4],\n",
            "        [47,  6],\n",
            "        [48, 11],\n",
            "        [49,  2],\n",
            "        [50,  3],\n",
            "        [51,  4],\n",
            "        [15,  6],\n",
            "        [52,  0],\n",
            "        [22,  1]]), Labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "Sample 4 - Features: tensor([[53, 11],\n",
            "        [17,  6],\n",
            "        [54,  8],\n",
            "        [55,  7],\n",
            "        [56,  7],\n",
            "        [57,  4],\n",
            "        [58,  6],\n",
            "        [59, 11],\n",
            "        [60,  3],\n",
            "        [17,  6],\n",
            "        [11,  5],\n",
            "        [61,  0],\n",
            "        [17,  6],\n",
            "        [11,  5],\n",
            "        [62,  0],\n",
            "        [63,  1]]), Labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "Sample 5 - Features: tensor([[11,  5],\n",
            "        [64,  0],\n",
            "        [15,  6],\n",
            "        [65,  0],\n",
            "        [66,  7],\n",
            "        [67,  2],\n",
            "        [36,  6],\n",
            "        [11,  5],\n",
            "        [32,  0],\n",
            "        [68,  0],\n",
            "        [10,  1],\n",
            "        [69, 12],\n",
            "        [24,  8],\n",
            "        [70,  7],\n",
            "        [30,  7],\n",
            "        [71, 10],\n",
            "        [72,  4],\n",
            "        [73,  0],\n",
            "        [74,  0],\n",
            "        [75,  0],\n",
            "        [76, 12],\n",
            "        [77,  4],\n",
            "        [13,  6],\n",
            "        [26,  5],\n",
            "        [78,  2],\n",
            "        [79,  3],\n",
            "        [80,  3],\n",
            "        [17,  6],\n",
            "        [11,  5],\n",
            "        [81,  0],\n",
            "        [82,  3],\n",
            "        [83, 12],\n",
            "        [15,  6],\n",
            "        [11,  5],\n",
            "        [84,  3],\n",
            "        [22,  1]]), Labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "Development Dataset Samples:\n",
            "Sample 1 - Features: tensor([[0, 0],\n",
            "        [1, 1],\n",
            "        [2, 2],\n",
            "        [3, 3],\n",
            "        [4, 1],\n",
            "        [5, 4],\n",
            "        [6, 5]]), Labels: tensor([0, 0, 0, 0, 0, 0, 0])\n",
            "Sample 2 - Features: tensor([[ 7,  2],\n",
            "        [ 8,  2],\n",
            "        [ 9,  0],\n",
            "        [10,  2],\n",
            "        [11,  3],\n",
            "        [12,  6],\n",
            "        [13,  4],\n",
            "        [14,  7],\n",
            "        [15,  3],\n",
            "        [16,  3],\n",
            "        [17,  4],\n",
            "        [ 9,  0],\n",
            "        [18,  8],\n",
            "        [19,  4],\n",
            "        [20,  0],\n",
            "        [ 1,  1],\n",
            "        [21,  2],\n",
            "        [22,  4],\n",
            "        [23,  5]]), Labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "Sample 3 - Features: tensor([[ 8,  2],\n",
            "        [11,  3],\n",
            "        [24,  2],\n",
            "        [25,  2],\n",
            "        [26,  2],\n",
            "        [27,  0],\n",
            "        [28,  1],\n",
            "        [29,  6],\n",
            "        [30,  5],\n",
            "        [31,  4],\n",
            "        [32,  4],\n",
            "        [33,  0],\n",
            "        [34,  8],\n",
            "        [35,  4],\n",
            "        [36,  0],\n",
            "        [ 1,  1],\n",
            "        [37,  8],\n",
            "        [38,  2],\n",
            "        [36,  0],\n",
            "        [ 1,  1],\n",
            "        [39,  2],\n",
            "        [36,  0],\n",
            "        [40,  2],\n",
            "        [41,  5],\n",
            "        [42,  3],\n",
            "        [43,  2],\n",
            "        [44,  2],\n",
            "        [45,  2],\n",
            "        [23,  5]]), Labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0])\n",
            "Sample 4 - Features: tensor([[46,  5]]), Labels: tensor([0])\n",
            "Sample 5 - Features: tensor([[ 8,  2],\n",
            "        [47,  9],\n",
            "        [11,  3],\n",
            "        [48,  2],\n",
            "        [49,  2],\n",
            "        [50,  2],\n",
            "        [51,  2],\n",
            "        [27,  0],\n",
            "        [28,  1],\n",
            "        [29,  6],\n",
            "        [30,  5],\n",
            "        [31,  4],\n",
            "        [32,  4],\n",
            "        [33,  0],\n",
            "        [34,  8],\n",
            "        [35,  4],\n",
            "        [36,  0],\n",
            "        [ 1,  1],\n",
            "        [39,  2],\n",
            "        [36,  0],\n",
            "        [40,  2],\n",
            "        [38,  2],\n",
            "        [36,  0],\n",
            "        [52,  2],\n",
            "        [41,  5],\n",
            "        [42,  3],\n",
            "        [53,  2],\n",
            "        [54,  2],\n",
            "        [55,  2],\n",
            "        [23,  5]]), Labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0])\n"
          ]
        }
      ]
    }
  ]
}